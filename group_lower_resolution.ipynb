{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c4daed-e5c7-45b5-a539-e00ababe62fc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-17T21:53:01.638127900Z",
     "start_time": "2024-06-17T21:52:55.404257800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac460ca9-d110-4c72-91de-191403cf1423",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-17T21:53:17.503265800Z",
     "start_time": "2024-06-17T21:53:10.660152900Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "230df90e-aa66-4211-a352-bfa4e09d3738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "# Import OS libraries\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# Data handling tools\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,  BatchNormalization, Activation, Dropout  \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from googleapiclient.discovery import build\n",
    "# from google.oauth2.credentials import Credentials\n",
    "# from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"GPU is available\" if tf.config.list_physical_devices('GPU') else \"GPU is not available\")\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e59583a-1f9a-4b27-9833-965d48e4c36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diretório onde estão armazenadas as imagens sem ser separadas por pastas\n",
    "image_dir = r'C:\\Users\\bruna\\OneDrive - Universidade do Minho\\Tese Mestrado em Bioinformática\\AGAR_dataset\\AGAR_dataset\\dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "501443d3-8e14-4b51-a414-cb99ce6c859f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(image_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize(target_size)  \n",
    "        return np.array(image) / 255.0  \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar a imagem {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45c9b597-d473-4e6f-af2a-11c62ebed05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carregar IDs do grupo de treinamento de um arquivo de texto\n",
    "train_ids_file = r'C:\\Users\\bruna\\OneDrive - Universidade do Minho\\Tese Mestrado em Bioinformática\\AGAR_dataset\\AGAR_dataset\\training_lists\\lower_resolution_train.txt'\n",
    "with open(train_ids_file, 'r') as file:\n",
    "    train_ids = [str(id) for id in json.loads(file.read())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8dab9cb2-9b5f-4939-9d61-43c6a43643ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carregar IDs do grupo de validação de um arquivo de texto\n",
    "val_ids_file = r'C:\\Users\\bruna\\OneDrive - Universidade do Minho\\Tese Mestrado em Bioinformática\\AGAR_dataset\\AGAR_dataset\\training_lists\\lower_resolution_val.txt'\n",
    "with open(val_ids_file, 'r') as file:\n",
    "    val_ids = [str(id) for id in json.loads(file.read())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "429b408f-c2e1-4905-9d3e-e98703e9f932",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs de treinamento carregados: ['16078', '16831', '16073', '16072', '16830'] ... (3319 no total)\n",
      "IDs de validação carregados: ['14175', '14176', '15540', '14172', '14678'] ... (1107 no total)\n"
     ]
    }
   ],
   "source": [
    "# Verificar se os IDs foram carregados corretamente\n",
    "print(f\"IDs de treinamento carregados: {train_ids[:5]} ... ({len(train_ids)} no total)\")\n",
    "print(f\"IDs de validação carregados: {val_ids[:5]} ... ({len(val_ids)} no total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6cd1513-e372-4372-a91c-ea0c5baea5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Lista para armazenar caminho da imagem e anotações correspondentes\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "# Iterar sobre todos os arquivos no diretório\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        # Construir o caminho completo do arquivo JSON\n",
    "        json_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        # Carregar o conteúdo do arquivo JSON\n",
    "        with open(json_path, 'r') as file:\n",
    "            try:\n",
    "                json_data = json.load(file)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Erro ao carregar JSON {json_path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Verificar se o sample_id está presente no JSON\n",
    "        sample_id = str(json_data.get('sample_id', None))\n",
    "        if sample_id is None:\n",
    "            print(f\"ID da amostra ausente no JSON: {json_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Construir o caminho completo do arquivo de imagem\n",
    "        image_filename = f\"{sample_id}.jpg\"\n",
    "        image_path = os.path.join(image_dir, image_filename)\n",
    "        \n",
    "        # Verificar se o arquivo de imagem existe\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Arquivo de imagem não encontrado: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Adicionar os dados à lista apropriada\n",
    "        data_tuple = (image_path, json_data)\n",
    "        if sample_id in train_ids:\n",
    "            train_data.append(data_tuple)\n",
    "            print(f\"Imagem de treinamento encontrada e carregada: {image_path}\")\n",
    "        elif sample_id in val_ids:\n",
    "            val_data.append(data_tuple)\n",
    "            print(f\"Imagem de validação encontrada e carregada: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f796c6f-0efa-4603-ac4a-b59a4c9b3d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de treinamento carregadas: 3318\n",
      "Número de imagens de validação carregadas: 1106\n"
     ]
    }
   ],
   "source": [
    "# Verificar o número de imagens carregadas\n",
    "print(f\"Número de imagens de treinamento carregadas: {len(train_data)}\")\n",
    "print(f\"Número de imagens de validação carregadas: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5e66225-7145-4d10-b260-0521212d8405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separar as imagens e os rótulos (labels) para treinamento\n",
    "train_images = [data[0] for data in train_data]\n",
    "train_labels = [data[1]['classes'][0] for data in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f5feae6-aa93-45d8-aa05-fc78a835fcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separar as imagens e os rótulos (labels) para validação\n",
    "val_images = [data[0] for data in val_data]\n",
    "val_labels = [data[1]['classes'][0] for data in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0d0f0ea-a9d9-4cd6-80af-2f8ef16df0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verificar se as listas estão vazias\n",
    "if len(train_images) == 0:\n",
    "    print(\"Nenhuma imagem de treinamento foi carregada.\")\n",
    "if len(val_images) == 0:\n",
    "    print(\"Nenhuma imagem de validação foi carregada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0327d58c-28c7-4f00-8723-e2a01e5ef0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtrar caminhos de imagem válidos\n",
    "train_images = [img for img in train_images if img is not None]\n",
    "val_images = [img for img in val_images if img is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dddeab36-e7d5-4947-bddb-9a0ec9820fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converter as imagens em tensores e normalizar, se necessário\n",
    "train_images = [load_image(image_path, target_size=(224, 224)) for image_path in train_images]\n",
    "val_images = [load_image(image_path, target_size=(224, 224)) for image_path in val_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c7a304f8-ed53-486f-bbd6-9832d526d2df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verificar se alguma imagem falhou ao carregar\n",
    "train_images = [img for img in train_images if img is not None]\n",
    "val_images = [img for img in val_images if img is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "01435733-935a-4fe1-82b0-3a8b5bf00c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de train_images antes da codificação: (3318, 224, 224, 3)\n",
      "Shape de train_labels antes da codificação: (3318,)\n",
      "Shape de val_images antes da codificação: (1106, 224, 224, 3)\n",
      "Shape de val_labels antes da codificação: (1106,)\n"
     ]
    }
   ],
   "source": [
    "# Verificar o shape das imagens e dos rótulos antes da codificação\n",
    "print(\"Shape de train_images antes da codificação:\", np.array(train_images).shape)\n",
    "print(\"Shape de train_labels antes da codificação:\", np.array(train_labels).shape)\n",
    "print(\"Shape de val_images antes da codificação:\", np.array(val_images).shape)\n",
    "print(\"Shape de val_labels antes da codificação:\", np.array(val_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b62f555-2787-4d07-b784-de6627676b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converter os rótulos em formato adequado (numérico), se necessário\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e805a3a7-ce69-4490-bca3-a7d4a6071166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de classes: 5\n"
     ]
    }
   ],
   "source": [
    "# Verificar o número de classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Número de classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "69a5651a-2f77-47f1-9d25-34b494ce261e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "#model.compile(optimizer='adam',\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9754a42-2e34-4397-b469-2fa262c6f52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de train_images após a divisão: (2654, 224, 224, 3)\n",
      "Shape de train_labels após a divisão: (2654,)\n",
      "Shape de val_images após a divisão: (664, 224, 224, 3)\n",
      "Shape de val_labels após a divisão: (664,)\n"
     ]
    }
   ],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e validação\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificar os shapes dos dados após a divisão\n",
    "print(\"Shape de train_images após a divisão:\", np.array(train_images).shape)\n",
    "print(\"Shape de train_labels após a divisão:\", np.array(train_labels).shape)\n",
    "print(\"Shape de val_images após a divisão:\", np.array(val_images).shape)\n",
    "print(\"Shape de val_labels após a divisão:\", np.array(val_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "30d19005-ce6b-4e78-81ee-04f09c3f7e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory to save the .npy files\n",
    "save_dir = r'C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_resolution'  \n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "881aaaf4-cd8c-49e5-aacc-74b0ee863b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to save numpy array as .npy file and return the path\n",
    "def save_image(image_array, save_dir, idx):\n",
    "    save_path = os.path.join(save_dir, f\"image_{idx}.npy\")\n",
    "    np.save(save_path, image_array)\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "76c9970b-5989-48f4-aad9-e0e2fd8d7674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save train images and get paths\n",
    "train_image_paths = [save_image(image, save_dir, idx) for idx, image in enumerate(train_images)]\n",
    "\n",
    "# Save val images and get paths\n",
    "val_image_paths = [save_image(image, save_dir, idx) for idx, image in enumerate(val_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2e0aaf8c-388b-4ccc-b407-07cc9e837695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create DataFrames\n",
    "train_df = pd.DataFrame({'image_path': train_image_paths, 'label': train_labels})\n",
    "val_df = pd.DataFrame({'image_path': val_image_paths, 'label': val_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4713c2a7-85f2-4b8a-b235-a23da442c533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  label\n",
       "0  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      3\n",
       "1  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      1\n",
       "2  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      1\n",
       "3  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      2\n",
       "4  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      2"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e3e28370-4ad0-4c2f-83ea-c0cfd6735e15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  label\n",
       "0  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      4\n",
       "1  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      2\n",
       "2  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      3\n",
       "3  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      2\n",
       "4  C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_re...      3"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a33918b1-b19d-40f2-aa01-391af37fbc23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training image paths:\n",
      "Valid path: C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_resolution\\image_0.npy\n",
      "\n",
      "Checking validation image paths:\n",
      "Valid path: C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_resolution\\image_0.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to check if the image paths in the DataFrame are valid\n",
    "def check_image_paths(df, column_name):\n",
    "    for path in df[column_name]:\n",
    "        if not os.path.isfile(path):\n",
    "            print(f\"Invalid path: {path}\")\n",
    "        else:\n",
    "            print(f\"Valid path: {path}\")\n",
    "            break\n",
    "\n",
    "# Check some paths in the training and validation DataFrames\n",
    "print(\"Checking training image paths:\")\n",
    "check_image_paths(train_df, 'image_path')\n",
    "\n",
    "print(\"\\nChecking validation image paths:\")\n",
    "check_image_paths(val_df, 'image_path')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2f2a7611-2dad-4138-be1d-f78edadff91c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 224, 224, 3) (0, 0)\n",
      "First image path in batch: C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_resolution\\image_0.npy\n"
     ]
    }
   ],
   "source": [
    "def npy_file_generator(dataframe, batch_size, input_size, mode='train'):\n",
    "    while True:\n",
    "        for start in range(0, len(dataframe), batch_size):\n",
    "            end = min(start + batch_size, len(dataframe))\n",
    "            batch_df = dataframe[start:end]\n",
    "            batch_images = []\n",
    "            for img_path in batch_df['image_path']:\n",
    "                img_array = np.load(img_path)\n",
    "                batch_images.append(img_array)\n",
    "            batch_images = np.array(batch_images)\n",
    "            if mode == 'train':\n",
    "                yield batch_images, batch_df['label'].values\n",
    "            elif mode == 'val':\n",
    "                yield batch_images, batch_df['label'].values\n",
    "            else:\n",
    "                print(f\"Unknown mode: {mode}\")\n",
    "\n",
    "            # Adicionar logs para depuração\n",
    "            print(f\"Processed batch from {start} to {end}\")\n",
    "\n",
    "# Verifique se os caminhos estão corretos no gerador personalizado\n",
    "for x, y in train_generator:\n",
    "    print(x.shape, y.shape)\n",
    "    print(f\"First image path in batch: {train_df.iloc[0]['image_path']}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9e8b1f4c-662f-454a-aa4f-639661a0b931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the custom data generators\n",
    "train_generator = npy_file_generator(train_df, batch_size=16, input_size=input_size, mode='train')\n",
    "val_generator = npy_file_generator(val_df, batch_size=16, input_size=input_size, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fa405c75-1287-48a7-8610-870055a6da4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 224, 224, 3) (16,)\n",
      "(16, 224, 224, 3) (16,)\n"
     ]
    }
   ],
   "source": [
    "# Test the generators\n",
    "for x, y in train_generator:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "for x, y in val_generator:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "becc4f0b-4786-48d2-86a7-747e90d6d623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training image paths:\n",
      "Valid path: C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_resolution\\image_0.npy\n",
      "\n",
      "Checking validation image paths:\n",
      "Valid path: C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_resolution\\image_0.npy\n",
      "Shape of the loaded image data from C:\\Users\\bruna\\OneDrive\\Tese mestrado\\lower_resolution\\image_0.npy: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check some paths in the training and validation DataFrames\n",
    "print(\"Checking training image paths:\")\n",
    "check_image_paths(train_df, 'image_path')\n",
    "\n",
    "print(\"\\nChecking validation image paths:\")\n",
    "check_image_paths(val_df, 'image_path')\n",
    "\n",
    "# Verify the content of one .npy file\n",
    "npy_file = train_df['image_path'].iloc[0]\n",
    "image_data = np.load(npy_file)\n",
    "print(f\"Shape of the loaded image data from {npy_file}: {image_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b6380248-cd00-4207-b1cc-b31a681f1b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['image_path'] = train_df['image_path'].apply(lambda x: os.path.abspath(x))\n",
    "val_df['image_path'] = val_df['image_path'].apply(lambda x: os.path.abspath(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "174dad62-ee67-40e7-b99e-d2dbcf121e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7b2fdc77-41d2-46b3-9173-b14c48fbc4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Criar um ImageDataGenerator para dados de treinamento com aumento de dados\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Criar um ImageDataGenerator para dados de validação (sem aumento de dados)\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Especificar o tamanho de entrada esperado pelo modelo\n",
    "input_size = (224, 224)\n",
    "\n",
    "# Criar geradores de dados para treinamento e validação\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=input_size,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "val_generator = valid_test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=input_size,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37454726-76dc-4b6d-9076-1193819cc165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:52:39.087606100Z",
     "start_time": "2024-06-17T21:52:38.244411800Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sample_images, sample_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(train_generator)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Display the images and labels\u001B[39;00m\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m12\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "sample_images, sample_labels = next(train_generator)\n",
    "\n",
    "# Display the images and labels\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(16):\n",
    "    image = sample_images[i]\n",
    "    label_index = np.argmax(sample_labels[i]) \n",
    "    label = list(train_generator.class_indices.keys())[label_index]  \n",
    "\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(label, color='k', fontsize=12)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26865f01-ccfa-4e0e-be13-550138fdc786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
