{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c4daed-e5c7-45b5-a539-e00ababe62fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:53:01.638127900Z",
     "start_time": "2024-06-17T21:52:55.404257800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac460ca9-d110-4c72-91de-191403cf1423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:53:17.503265800Z",
     "start_time": "2024-06-17T21:53:10.660152900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230df90e-aa66-4211-a352-bfa4e09d3738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "# Import OS libraries\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# Data handling tools\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,  BatchNormalization, Activation, Dropout  \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from googleapiclient.discovery import build\n",
    "# from google.oauth2.credentials import Credentials\n",
    "# from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"GPU is available\" if tf.config.list_physical_devices('GPU') else \"GPU is not available\")\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e59583a-1f9a-4b27-9833-965d48e4c36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diretório onde estão armazenadas as imagens sem ser separadas por pastas\n",
    "image_dir = r'C:\\Users\\bruna\\OneDrive - Universidade do Minho\\Tese Mestrado em Bioinformática\\AGAR_dataset\\AGAR_dataset\\dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501443d3-8e14-4b51-a414-cb99ce6c859f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(image_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize(target_size)  \n",
    "        return np.array(image) / 255.0  \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar a imagem {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c9b597-d473-4e6f-af2a-11c62ebed05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carregar IDs do grupo de treinamento de um arquivo de texto\n",
    "train_ids_file = r'C:\\Users\\bruna\\OneDrive - Universidade do Minho\\Tese Mestrado em Bioinformática\\AGAR_dataset\\AGAR_dataset\\training_lists\\lower_resolution_train.txt'\n",
    "with open(train_ids_file, 'r') as file:\n",
    "    train_ids = [str(id) for id in json.loads(file.read())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dab9cb2-9b5f-4939-9d61-43c6a43643ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carregar IDs do grupo de validação de um arquivo de texto\n",
    "val_ids_file = r'C:\\Users\\bruna\\OneDrive - Universidade do Minho\\Tese Mestrado em Bioinformática\\AGAR_dataset\\AGAR_dataset\\training_lists\\lower_resolution_val.txt'\n",
    "with open(val_ids_file, 'r') as file:\n",
    "    val_ids = [str(id) for id in json.loads(file.read())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "429b408f-c2e1-4905-9d3e-e98703e9f932",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs de treinamento carregados: ['16078', '16831', '16073', '16072', '16830'] ... (3319 no total)\n",
      "IDs de validação carregados: ['14175', '14176', '15540', '14172', '14678'] ... (1107 no total)\n"
     ]
    }
   ],
   "source": [
    "# Verificar se os IDs foram carregados corretamente\n",
    "print(f\"IDs de treinamento carregados: {train_ids[:5]} ... ({len(train_ids)} no total)\")\n",
    "print(f\"IDs de validação carregados: {val_ids[:5]} ... ({len(val_ids)} no total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cd1513-e372-4372-a91c-ea0c5baea5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Lista para armazenar caminho da imagem e anotações correspondentes\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "# Iterar sobre todos os arquivos no diretório\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        # Construir o caminho completo do arquivo JSON\n",
    "        json_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        # Carregar o conteúdo do arquivo JSON\n",
    "        with open(json_path, 'r') as file:\n",
    "            try:\n",
    "                json_data = json.load(file)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Erro ao carregar JSON {json_path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Verificar se o sample_id está presente no JSON\n",
    "        sample_id = str(json_data.get('sample_id', None))\n",
    "        if sample_id is None:\n",
    "            print(f\"ID da amostra ausente no JSON: {json_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Construir o caminho completo do arquivo de imagem\n",
    "        image_filename = f\"{sample_id}.jpg\"\n",
    "        image_path = os.path.join(image_dir, image_filename)\n",
    "        \n",
    "        # Verificar se o arquivo de imagem existe\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Arquivo de imagem não encontrado: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Adicionar os dados à lista apropriada\n",
    "        data_tuple = (image_path, json_data)\n",
    "        if sample_id in train_ids:\n",
    "            train_data.append(data_tuple)\n",
    "            print(f\"Imagem de treinamento encontrada e carregada: {image_path}\")\n",
    "        elif sample_id in val_ids:\n",
    "            val_data.append(data_tuple)\n",
    "            print(f\"Imagem de validação encontrada e carregada: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f796c6f-0efa-4603-ac4a-b59a4c9b3d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de treinamento carregadas: 3318\n",
      "Número de imagens de validação carregadas: 1106\n"
     ]
    }
   ],
   "source": [
    "# Verificar o número de imagens carregadas\n",
    "print(f\"Número de imagens de treinamento carregadas: {len(train_data)}\")\n",
    "print(f\"Número de imagens de validação carregadas: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e66225-7145-4d10-b260-0521212d8405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separar as imagens e os rótulos (labels) para treinamento\n",
    "train_images = [data[0] for data in train_data]\n",
    "train_labels = [data[1]['classes'][0] for data in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f5feae6-aa93-45d8-aa05-fc78a835fcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separar as imagens e os rótulos (labels) para validação\n",
    "val_images = [data[0] for data in val_data]\n",
    "val_labels = [data[1]['classes'][0] for data in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0d0f0ea-a9d9-4cd6-80af-2f8ef16df0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verificar se as listas estão vazias\n",
    "if len(train_images) == 0:\n",
    "    print(\"Nenhuma imagem de treinamento foi carregada.\")\n",
    "if len(val_images) == 0:\n",
    "    print(\"Nenhuma imagem de validação foi carregada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0327d58c-28c7-4f00-8723-e2a01e5ef0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtrar caminhos de imagem válidos\n",
    "train_images = [img for img in train_images if img is not None]\n",
    "val_images = [img for img in val_images if img is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dddeab36-e7d5-4947-bddb-9a0ec9820fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converter as imagens em tensores e normalizar, se necessário\n",
    "train_images = [load_image(image_path, target_size=(224, 224)) for image_path in train_images]\n",
    "val_images = [load_image(image_path, target_size=(224, 224)) for image_path in val_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a304f8-ed53-486f-bbd6-9832d526d2df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verificar se alguma imagem falhou ao carregar\n",
    "train_images = [img for img in train_images if img is not None]\n",
    "val_images = [img for img in val_images if img is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01435733-935a-4fe1-82b0-3a8b5bf00c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de train_images antes da codificação: (2123, 224, 224, 3)\n",
      "Shape de train_labels antes da codificação: (2123,)\n",
      "Shape de val_images antes da codificação: (531, 224, 224, 3)\n",
      "Shape de val_labels antes da codificação: (531,)\n"
     ]
    }
   ],
   "source": [
    "# Verificar o shape das imagens e dos rótulos antes da codificação\n",
    "print(\"Shape de train_images antes da codificação:\", np.array(train_images).shape)\n",
    "print(\"Shape de train_labels antes da codificação:\", np.array(train_labels).shape)\n",
    "print(\"Shape de val_images antes da codificação:\", np.array(val_images).shape)\n",
    "print(\"Shape de val_labels antes da codificação:\", np.array(val_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b62f555-2787-4d07-b784-de6627676b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converter os rótulos em formato adequado (numérico), se necessário\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e805a3a7-ce69-4490-bca3-a7d4a6071166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de classes: 5\n"
     ]
    }
   ],
   "source": [
    "# Verificar o número de classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Número de classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9754a42-2e34-4397-b469-2fa262c6f52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de train_images após a divisão: (1698, 224, 224, 3)\n",
      "Shape de train_labels após a divisão: (1698,)\n",
      "Shape de val_images após a divisão: (425, 224, 224, 3)\n",
      "Shape de val_labels após a divisão: (425,)\n"
     ]
    }
   ],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e validação\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificar os shapes dos dados após a divisão\n",
    "print(\"Shape de train_images após a divisão:\", np.array(train_images).shape)\n",
    "print(\"Shape de train_labels após a divisão:\", np.array(train_labels).shape)\n",
    "print(\"Shape de val_images após a divisão:\", np.array(val_images).shape)\n",
    "print(\"Shape de val_labels após a divisão:\", np.array(val_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c15ab73c-ee6f-412d-b26e-82adcf9d53f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de train_labels_one_hot após o one-hot encoding: (1698, 5)\n",
      "Shape de val_labels_one_hot após o one-hot encoding: (425, 5)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding dos rótulos após a divisão\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_labels.reshape(-1, 1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_labels.reshape(-1, 1))\n",
    "\n",
    "# Verificar os shapes dos rótulos one-hot encoded\n",
    "print(\"Shape de train_labels_one_hot após o one-hot encoding:\", train_labels_one_hot.shape)\n",
    "print(\"Shape de val_labels_one_hot após o one-hot encoding:\", val_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23328d9a-88cf-48c9-b4bb-af4daf70214e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Criar o modelo da CNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')  # Número de classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f180d1f-ce25-44a1-9a42-92c5c4d31a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Compilar o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a48ccf6-aeeb-4aad-a062-fa043455a607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 101s 2s/step - loss: 1.4150 - accuracy: 0.3681 - val_loss: 1.2976 - val_accuracy: 0.3506\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 95s 2s/step - loss: 1.2020 - accuracy: 0.4211 - val_loss: 1.2986 - val_accuracy: 0.3624\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 90s 2s/step - loss: 1.0151 - accuracy: 0.5554 - val_loss: 0.8861 - val_accuracy: 0.6188\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 91s 2s/step - loss: 0.8386 - accuracy: 0.6437 - val_loss: 0.6956 - val_accuracy: 0.7224\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 90s 2s/step - loss: 0.7001 - accuracy: 0.7126 - val_loss: 0.6347 - val_accuracy: 0.7012\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 92s 2s/step - loss: 0.5798 - accuracy: 0.7721 - val_loss: 0.6908 - val_accuracy: 0.7412\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 99s 2s/step - loss: 0.5759 - accuracy: 0.7833 - val_loss: 0.4035 - val_accuracy: 0.8776\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 94s 2s/step - loss: 0.4698 - accuracy: 0.8139 - val_loss: 0.3849 - val_accuracy: 0.8659\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 95s 2s/step - loss: 0.4039 - accuracy: 0.8534 - val_loss: 0.3486 - val_accuracy: 0.8941\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 92s 2s/step - loss: 0.3586 - accuracy: 0.8681 - val_loss: 0.3075 - val_accuracy: 0.9035\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(train_images, train_labels_one_hot, epochs=10, batch_size=32, \n",
    "                    validation_data=(val_images, val_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de701cf0-6057-4e4c-a1ea-a1f41b80c1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 4s - loss: 0.3075 - accuracy: 0.9035 - 4s/epoch - 262ms/step\n",
      "Acurácia na validação: 90.35%\n"
     ]
    }
   ],
   "source": [
    "#  Avaliar o modelo\n",
    "val_loss, val_acc = model.evaluate(val_images, val_labels_one_hot, verbose=2)\n",
    "print(f\"Acurácia na validação: {val_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f660822-5c9f-4cc8-8c4d-ba4c5bb17899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4ecb0-4b65-4564-9f07-7af426a21274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37454726-76dc-4b6d-9076-1193819cc165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:52:39.087606100Z",
     "start_time": "2024-06-17T21:52:38.244411800Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sample_images, sample_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_generator)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Display the images and labels\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "sample_images, sample_labels = next(train_generator)\n",
    "\n",
    "# Display the images and labels\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(16):\n",
    "    image = sample_images[i]\n",
    "    label_index = np.argmax(sample_labels[i]) \n",
    "    label = list(train_generator.class_indices.keys())[label_index]  \n",
    "\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(label, color='k', fontsize=12)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26865f01-ccfa-4e0e-be13-550138fdc786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
