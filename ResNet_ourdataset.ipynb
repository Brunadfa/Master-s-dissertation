{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "27a9f128-bc51-4bc1-a9e1-697039e0755b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f8328dc3-9282-4547-99b8-0d4ca02ba91a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "# Verificar se a GPU está disponível\n",
    "print(\"GPU is available\" if tf.config.list_physical_devices('GPU') else \"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1012ecbf-573b-469d-add9-be0c59c53fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diretório onde estão armazenadas as imagens sem ser separadas por pastas\n",
    "base_dir = r'C:\\Users\\bruna\\OneDrive\\Microbialdataset\\images_new_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7f8cc566-a060-46fe-b6c5-69e9f72a754f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configurações\n",
    "img_height, img_width = 112, 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "69aa18e1-bf15-4f89-9bd6-ce2429b0eef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Carregar as imagens e rótulos\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Mapeia as classes para índices\n",
    "class_names = os.listdir(base_dir)\n",
    "class_indices = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "        img = load_img(img_path, target_size=(img_height, img_width))\n",
    "        img_array = img_to_array(img) / 255.0  # Normalizar\n",
    "        images.append(img_array)\n",
    "        labels.append(class_indices[class_name])\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3968a05b-3020-4109-b8f2-284d37b3c6ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "47faeaa4-9947-47f4-9ea6-cb02ad746ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converter os rótulos para one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=len(class_names))\n",
    "y_test = to_categorical(y_test, num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dbe7f031-d515-435e-8ce9-0c4354fb67f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cf0b0c47-3503-4d4e-81e8-118815dee82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ajustar os geradores com os dados de treinamento\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "570203e0-f162-4d21-8a99-d0cb237802ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para o conjunto de teste, apenas a normalização\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e04644cb-fdb4-4b21-94d9-a23c9f148dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Carregar o modelo base ResNet50 com pesos pré-treinados da ImageNet\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d6a70dcf-605e-4fb0-805b-514ee8602f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True  # Descongelar o modelo\n",
    "for layer in base_model.layers[:143]:  # Manter as primeiras 143 camadas congeladas\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "88f4f276-d58e-46dd-88b8-4fbf2532f84b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)  # Camada extra\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(class_names), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6abfd3bf-9118-4fc2-8ba7-a36ccb995d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criar o modelo final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "92bf7af6-1e33-4af4-8bd1-60d8affb39e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recompilar o modelo\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ed9a97e7-be43-48e0-b4a6-a68cb517a427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7298 - accuracy: 0.3750 - val_loss: 0.9353 - val_accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8998 - accuracy: 0.6250 - val_loss: 0.9078 - val_accuracy: 0.3333\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 1.0040 - accuracy: 0.5000 - val_loss: 0.9239 - val_accuracy: 0.3333\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.9100 - accuracy: 0.5000 - val_loss: 0.9521 - val_accuracy: 0.3333\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7053 - accuracy: 0.6250 - val_loss: 0.9764 - val_accuracy: 0.3333\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6584 - accuracy: 0.7500 - val_loss: 1.0046 - val_accuracy: 0.3333\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1615 - accuracy: 0.5000 - val_loss: 0.9786 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bcbd3-961a-4be3-b960-7f4d24b449d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9372a-836e-47e6-91f4-420001bcae42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
